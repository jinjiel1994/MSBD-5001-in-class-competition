{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/train.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_free: boolean => map 0/1\n",
    "data = data.drop(columns=['is_free'])\n",
    "\n",
    "# Top 2 is way larger and may have negative effect to the whole dataset. So will be removed.\n",
    "data = data.drop(data['price'].nlargest(2).index)\n",
    "\n",
    "# price: discrete number => scaling\n",
    "# data['price'] = data['price'] / 30000\n",
    "\n",
    "# genres: string => split and dummy (pivot)\n",
    "# genres_split = data['genres'].apply(lambda x: x.strip().split(\",\"))\n",
    "# genres = pd.get_dummies(genres_split.apply(pd.Series).stack()).sum(level=0)\n",
    "# genres.columns = pd.MultiIndex.from_product([['genres'], genres.columns])\n",
    "# data = data.drop(columns=['genres'])\n",
    "# data = pd.concat([data, genres], axis=1)\n",
    "data = data.drop(columns=['genres'])\n",
    "\n",
    "\n",
    "# categories: stirng => split and dummy (pivot)\n",
    "# categories_split = data['categories'].apply(lambda x: x.strip().split(\",\"))\n",
    "# categories = pd.get_dummies(categories_split.apply(pd.Series).stack()).sum(level=0)\n",
    "# categories.columns = pd.MultiIndex.from_product([['categories'], categories.columns])\n",
    "# data = data.drop(columns=['categories'])\n",
    "# data = pd.concat([data, categories], axis=1)\n",
    "data = data.drop(columns=['categories'])\n",
    "\n",
    "# tags: string => count its numbers of letter and catogorize\n",
    "# data['tags'] = data['tags'].apply(len)\n",
    "# data.loc[data['tags'] <= 170, 'tags'] = 0\n",
    "# data.loc[(data['tags'] > 170) & (data['tags'] <= 197), 'tags'] = 0.25\n",
    "# data.loc[(data['tags'] > 197) & (data['tags'] <= 213), 'tags'] = 0.5\n",
    "# data.loc[data['tags'] > 213, 'tags'] = 1\n",
    "data = data.drop(columns['tags']\n",
    "\n",
    "# purchase_date, release_date: date => convert to stamptime and count the differece bewteen them as well as now\n",
    "# Drop the examples with NaN value\n",
    "data = data.drop(data.loc[data['purchase_date'].isna(), :].index)\n",
    "data['purchase_date'] = data['purchase_date'].apply(lambda x: datetime.strptime(x, '%b %d, %Y'))\n",
    "data.loc[data['release_date'] == 'Nov 10, 2016', 'release_date'] = '10 Nov, 2016' # Exception \n",
    "data['release_date'] = data['release_date'].apply(lambda x: datetime.strptime(x, '%d %b, %Y'))\n",
    "data['day_btn_purchase_release'] = (data['purchase_date'] - data['release_date']).dt.days\n",
    "data['day_btn_2020_purchase'] = (datetime(2020,1,1)-data['purchase_date']).dt.days\n",
    "# data['day_btn_purchase_release'] divided by 5000\n",
    "data['day_btn_purchase_release'] = data['day_btn_purchase_release'] / 5000\n",
    "# data['day_btn_2020_purchase'] divided by 2000\n",
    "data['day_btn_2020_purchase'] = data['day_btn_2020_purchase'] / 2000\n",
    "# Remove purchase_date and release_date\n",
    "data = data.drop(columns=['purchase_date', 'release_date'])\n",
    "\n",
    "# total_positive_reviews: float => scaling\n",
    "# total_negative_reviews: float => scaling\n",
    "# Divided by 100000\n",
    "data['total_positive_reviews'] = data['total_positive_reviews'] / 100000\n",
    "# Divided by 100000\n",
    "data['total_negative_reviews'] = data['total_negative_reviews'] / 100000\n",
    "\n",
    "# Save the prepocsssing data\n",
    "data.to_csv('data/prepocessed_train_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing for  test data\n",
    "playtime_forever: output\\\n",
    "is_free: boolean => map 0/1\\\n",
    "price: discrete number => scaling\\\n",
    "genres: string => split and dummy (pivot)\\\n",
    "categories: stirng => split and dummy (pivot)\\\n",
    "tags: string => count its numbers of letter and catogorize\\\n",
    "purchase_date, release_date: date => convert to stamptime and count the differece bewteen them as well as now\\\n",
    "total_positive_reviews: float => scaling\\\n",
    "total_negative_reviews: float => scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_free: boolean => map 0/1\n",
    "test_data['is_free'] = test_data['is_free'].map({False:0, True:1})\n",
    "\n",
    "# price: discrete number => scaling\n",
    "test_data['price'] = test_data['price'] / 30000\n",
    "\n",
    "# genres: string => split and dummy (pivot)\n",
    "genres_split = test_data['genres'].apply(lambda x: x.strip().split(\",\"))\n",
    "genres = pd.get_dummies(genres_split.apply(pd.Series).stack()).sum(level=0)\n",
    "genres.columns = pd.MultiIndex.from_product([['genres'], genres.columns])\n",
    "test_data = test_data.drop(columns=['genres'])\n",
    "test_data = pd.concat([test_data, genres], axis=1)\n",
    "\n",
    "# categories: stirng => split and dummy (pivot)\n",
    "categories_split = test_data['categories'].apply(lambda x: x.strip().split(\",\"))\n",
    "categories = pd.get_dummies(categories_split.apply(pd.Series).stack()).sum(level=0)\n",
    "categories.columns = pd.MultiIndex.from_product([['categories'], categories.columns])\n",
    "test_data = test_data.drop(columns=['categories'])\n",
    "test_data = pd.concat([test_data, categories], axis=1)\n",
    "\n",
    "# tags: string => count its numbers of letter and catogorize\n",
    "test_data['tags'] = test_data['tags'].apply(len)\n",
    "test_data.loc[test_data['tags'] <= 170, 'tags'] = 0\n",
    "test_data.loc[(test_data['tags'] > 170) & (test_data['tags'] <= 197), 'tags'] = 0.25\n",
    "test_data.loc[(test_data['tags'] > 197) & (test_data['tags'] <= 213), 'tags'] = 0.5\n",
    "test_data.loc[test_data['tags'] > 213, 'tags'] = 0.75\n",
    "\n",
    "# purchase_date, release_date: date => convert to stamptime and count the differece bewteen them as well as now\n",
    "test_data['purchase_date'] = test_data['purchase_date'].fillna(\"Sep 2, 2019\")\n",
    "test_data['purchase_date'] = test_data['purchase_date'].apply(lambda x: datetime.strptime(x, '%b %d, %Y'))\n",
    "test_data['release_date'] = test_data['release_date'].apply(lambda x: datetime.strptime(x, '%d-%b-%y'))\n",
    "test_data['day_btn_purchase_release'] = (test_data['purchase_date'] - test_data['release_date']).dt.days\n",
    "test_data['day_btn_2020_purchase'] = (datetime(2020,1,1)-test_data['purchase_date']).dt.days\n",
    "test_data['day_btn_purchase_release'] = test_data['day_btn_purchase_release'] / 5000\n",
    "test_data['day_btn_2020_purchase'] = test_data['day_btn_2020_purchase'] / 2000\n",
    "test_data = test_data.drop(columns=['purchase_date', 'release_date'])\n",
    "\n",
    "# total_positive_reviews: float => scaling\n",
    "# total_negative_reviews: float => scaling\n",
    "test_data['total_positive_reviews'] = test_data['total_positive_reviews'].fillna(0)\n",
    "test_data['total_negative_reviews'] = test_data['total_negative_reviews'].fillna(0)\n",
    "test_data['total_positive_reviews'] = test_data['total_positive_reviews'] / 100000\n",
    "test_data['total_negative_reviews'] = test_data['total_negative_reviews'] / 100000\n",
    "\n",
    "test_data[('genres', 'Racing')] = 0\n",
    "test_data[('genres', 'Design & Illustration')] = 0\n",
    "test_data[('genres', 'Utilities')] = 0\n",
    "test_data[('genres', 'Sexual Content')] = 0\n",
    "test_data[('categories', 'Valve Anti-Cheat enabled')] = 0\n",
    "test_data[('genres', 'Animation & Modeling')] = 0\n",
    "test_data[('genres', 'Audio Production')] = 0\n",
    "test_data['playtime_forever'] = 0\n",
    "\n",
    "# Reorder\n",
    "test_data = test_data[data.columns]\n",
    "test_data = test_data.drop(columns=['playtime_forever'])\n",
    "\n",
    "# Save to csv\n",
    "test_data.to_csv('../data/prepocessed_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
